{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task_04 : Image-to-Image Translation with cGAN**"
      ],
      "metadata": {
        "id": "ckC9nWgEWcCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implement an image-to-image translation model using a conditional generative adversarial network (cGAN) called pix2pix.*"
      ],
      "metadata": {
        "id": "miTQQbJmWctI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Iec4GWYA5SL-",
        "outputId": "60ec7761-029b-4615-8403-5d1719e0e501"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BQbTc98Yy1O-",
        "outputId": "141f295d-9ff0-415f-8381-652589c1cc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import os\n"
      ],
      "metadata": {
        "id": "3fCfQmpe1Yo9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act='relu', use_dropout=False):\n",
        "        super().__init__()\n",
        "        self.down = down\n",
        "        self.act = nn.ReLU() if act == 'relu' else nn.LeakyReLU(0.2)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False) if down \\\n",
        "                    else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False)\n",
        "        self.norm = nn.BatchNorm2d(out_channels)\n",
        "        self.dropout = nn.Dropout(0.5) if use_dropout else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.act(x)\n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.down1 = UNetBlock(in_channels, 64, act='lrelu', use_dropout=False)\n",
        "        self.down2 = UNetBlock(64, 128, act='lrelu')\n",
        "        self.down3 = UNetBlock(128, 256, act='lrelu')\n",
        "        self.down4 = UNetBlock(256, 512, act='lrelu')\n",
        "        self.down5 = UNetBlock(512, 512, act='lrelu')\n",
        "        self.down6 = UNetBlock(512, 512, act='lrelu')\n",
        "        self.down7 = UNetBlock(512, 512, act='lrelu')\n",
        "        self.bottleneck = UNetBlock(512, 512, act='relu')\n",
        "\n",
        "        self.up1 = UNetBlock(512, 512, down=False, use_dropout=True)\n",
        "        self.up2 = UNetBlock(1024, 512, down=False, use_dropout=True)\n",
        "        self.up3 = UNetBlock(1024, 512, down=False, use_dropout=True)\n",
        "        self.up4 = UNetBlock(1024, 512, down=False)\n",
        "        self.up5 = UNetBlock(1024, 256, down=False)\n",
        "        self.up6 = UNetBlock(512, 128, down=False)\n",
        "        self.up7 = UNetBlock(256, 64, down=False)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "        d7 = self.down7(d6)\n",
        "        bn = self.bottleneck(d7)\n",
        "\n",
        "        u1 = self.up1(bn)\n",
        "        u2 = self.up2(torch.cat([u1, d7], 1))\n",
        "        u3 = self.up3(torch.cat([u2, d6], 1))\n",
        "        u4 = self.up4(torch.cat([u3, d5], 1))\n",
        "        u5 = self.up5(torch.cat([u4, d4], 1))\n",
        "        u6 = self.up6(torch.cat([u5, d3], 1))\n",
        "        u7 = self.up7(torch.cat([u6, d2], 1))\n",
        "\n",
        "        return self.final(torch.cat([u7, d1], 1))\n"
      ],
      "metadata": {
        "id": "bVeIDLHx1ffs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        def block(in_c, out_c, norm=True):\n",
        "            layers = [nn.Conv2d(in_c, out_c, 4, 2, 1)]\n",
        "            if norm:\n",
        "                layers.append(nn.BatchNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels * 2, 64, norm=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, 1, 1)  # Patch output\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # x: input image, y: target or generated image\n",
        "        return self.model(torch.cat([x, y], dim=1))\n"
      ],
      "metadata": {
        "id": "mUOeBUh51jpk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_L1 = nn.L1Loss()\n"
      ],
      "metadata": {
        "id": "d1YmqxNQ2Cp-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, generator, discriminator, g_optimizer, d_optimizer, device):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for epoch in range(100):\n",
        "        for i, (input_image, target_image) in enumerate(dataloader):\n",
        "            input_image = input_image.to(device)\n",
        "            target_image = target_image.to(device)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "            fake_image = generator(input_image)\n",
        "            real_pred = discriminator(input_image, target_image)\n",
        "            fake_pred = discriminator(input_image, fake_image.detach())\n",
        "\n",
        "            real_loss = criterion_GAN(real_pred, torch.ones_like(real_pred))\n",
        "            fake_loss = criterion_GAN(fake_pred, torch.zeros_like(fake_pred))\n",
        "            d_loss = (real_loss + fake_loss) * 0.5\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "            fake_pred = discriminator(input_image, fake_image)\n",
        "            gan_loss = criterion_GAN(fake_pred, torch.ones_like(fake_pred))\n",
        "            l1 = criterion_L1(fake_image, target_image) * 100\n",
        "\n",
        "            g_loss = gan_loss + l1\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "        save_image(fake_image[:4], f\"outputs/fake_{epoch}.png\", nrow=2, normalize=True)\n"
      ],
      "metadata": {
        "id": "r1Rt5B2F2HY1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "class PairedImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.input_dir = os.path.join(root_dir, \"input\")\n",
        "        self.target_dir = os.path.join(root_dir, \"target\")\n",
        "        self.filenames = sorted(os.listdir(self.input_dir))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_path = os.path.join(self.input_dir, self.filenames[idx])\n",
        "        target_path = os.path.join(self.target_dir, self.filenames[idx])\n",
        "\n",
        "        input_image = Image.open(input_path).convert(\"RGB\")\n",
        "        target_image = Image.open(target_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            target_image = self.transform(target_image)\n",
        "\n",
        "        return input_image, target_image\n"
      ],
      "metadata": {
        "id": "02mGN8bg2MZ_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = PairedImageDataset(\"/content/drive/MyDrive/pix2pix_sample_paired_dataset\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "dl0Z5dDU3mPl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "G = GeneratorUNet().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "train(dataloader, G, D, g_optimizer, d_optimizer, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O9732i9O5okc",
        "outputId": "605df697-0f6e-40bb-b466-65debf5851c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0] | D Loss: 0.3491 | G Loss: 47.8418\n",
            "Epoch [1] | D Loss: 0.1102 | G Loss: 36.4447\n",
            "Epoch [2] | D Loss: 0.1326 | G Loss: 32.4275\n",
            "Epoch [3] | D Loss: 0.2928 | G Loss: 22.4157\n",
            "Epoch [4] | D Loss: 0.1273 | G Loss: 18.9906\n",
            "Epoch [5] | D Loss: 0.0692 | G Loss: 18.6607\n",
            "Epoch [6] | D Loss: 0.0633 | G Loss: 16.4297\n",
            "Epoch [7] | D Loss: 0.0845 | G Loss: 16.1534\n",
            "Epoch [8] | D Loss: 0.0771 | G Loss: 13.9206\n",
            "Epoch [9] | D Loss: 0.1926 | G Loss: 14.6335\n",
            "Epoch [10] | D Loss: 0.0414 | G Loss: 13.0245\n",
            "Epoch [11] | D Loss: 0.0472 | G Loss: 12.0464\n",
            "Epoch [12] | D Loss: 0.0720 | G Loss: 11.1387\n",
            "Epoch [13] | D Loss: 0.0496 | G Loss: 11.6159\n",
            "Epoch [14] | D Loss: 0.3072 | G Loss: 10.0608\n",
            "Epoch [15] | D Loss: 0.1686 | G Loss: 10.6748\n",
            "Epoch [16] | D Loss: 0.0225 | G Loss: 10.4104\n",
            "Epoch [17] | D Loss: 0.0572 | G Loss: 10.2415\n",
            "Epoch [18] | D Loss: 0.0776 | G Loss: 10.1839\n",
            "Epoch [19] | D Loss: 0.1796 | G Loss: 9.9946\n",
            "Epoch [20] | D Loss: 0.1805 | G Loss: 9.0807\n",
            "Epoch [21] | D Loss: 0.0944 | G Loss: 9.2263\n",
            "Epoch [22] | D Loss: 0.1204 | G Loss: 8.7387\n",
            "Epoch [23] | D Loss: 0.2539 | G Loss: 8.3314\n",
            "Epoch [24] | D Loss: 0.1059 | G Loss: 8.0074\n",
            "Epoch [25] | D Loss: 0.2500 | G Loss: 7.6692\n",
            "Epoch [26] | D Loss: 0.1209 | G Loss: 8.0027\n",
            "Epoch [27] | D Loss: 0.0774 | G Loss: 7.4551\n",
            "Epoch [28] | D Loss: 0.0309 | G Loss: 8.1976\n",
            "Epoch [29] | D Loss: 0.0215 | G Loss: 7.6627\n",
            "Epoch [30] | D Loss: 0.2584 | G Loss: 8.4302\n",
            "Epoch [31] | D Loss: 2.7027 | G Loss: 7.0030\n",
            "Epoch [32] | D Loss: 0.2823 | G Loss: 6.9542\n",
            "Epoch [33] | D Loss: 0.2499 | G Loss: 6.5472\n",
            "Epoch [34] | D Loss: 0.2464 | G Loss: 6.4032\n",
            "Epoch [35] | D Loss: 0.2441 | G Loss: 6.4881\n",
            "Epoch [36] | D Loss: 0.2444 | G Loss: 6.7133\n",
            "Epoch [37] | D Loss: 0.2437 | G Loss: 6.2577\n",
            "Epoch [38] | D Loss: 0.2424 | G Loss: 6.1742\n",
            "Epoch [39] | D Loss: 0.2392 | G Loss: 5.8745\n",
            "Epoch [40] | D Loss: 0.2369 | G Loss: 5.9177\n",
            "Epoch [41] | D Loss: 0.2318 | G Loss: 6.0013\n",
            "Epoch [42] | D Loss: 0.2247 | G Loss: 6.2604\n",
            "Epoch [43] | D Loss: 0.2242 | G Loss: 5.8979\n",
            "Epoch [44] | D Loss: 0.2176 | G Loss: 6.0493\n",
            "Epoch [45] | D Loss: 0.2053 | G Loss: 5.5306\n",
            "Epoch [46] | D Loss: 0.2067 | G Loss: 6.0947\n",
            "Epoch [47] | D Loss: 0.1865 | G Loss: 6.0109\n",
            "Epoch [48] | D Loss: 0.1833 | G Loss: 5.7530\n",
            "Epoch [49] | D Loss: 0.2044 | G Loss: 5.6625\n",
            "Epoch [50] | D Loss: 0.1560 | G Loss: 5.8133\n",
            "Epoch [51] | D Loss: 0.1485 | G Loss: 6.3347\n",
            "Epoch [52] | D Loss: 0.1297 | G Loss: 6.1105\n",
            "Epoch [53] | D Loss: 0.1322 | G Loss: 5.6852\n",
            "Epoch [54] | D Loss: 0.1481 | G Loss: 6.0378\n",
            "Epoch [55] | D Loss: 0.1217 | G Loss: 5.9040\n",
            "Epoch [56] | D Loss: 0.0964 | G Loss: 5.5309\n",
            "Epoch [57] | D Loss: 0.0632 | G Loss: 5.8120\n",
            "Epoch [58] | D Loss: 0.1025 | G Loss: 5.6588\n",
            "Epoch [59] | D Loss: 0.1373 | G Loss: 5.9688\n",
            "Epoch [60] | D Loss: 0.0423 | G Loss: 5.5664\n",
            "Epoch [61] | D Loss: 0.0998 | G Loss: 5.6262\n",
            "Epoch [62] | D Loss: 0.0706 | G Loss: 5.9603\n",
            "Epoch [63] | D Loss: 0.0350 | G Loss: 5.4239\n",
            "Epoch [64] | D Loss: 0.0573 | G Loss: 5.4345\n",
            "Epoch [65] | D Loss: 0.0241 | G Loss: 5.5225\n",
            "Epoch [66] | D Loss: 0.0247 | G Loss: 5.6821\n",
            "Epoch [67] | D Loss: 0.0606 | G Loss: 5.9853\n",
            "Epoch [68] | D Loss: 0.0324 | G Loss: 5.9433\n",
            "Epoch [69] | D Loss: 0.1198 | G Loss: 5.3971\n",
            "Epoch [70] | D Loss: 0.0768 | G Loss: 4.9451\n",
            "Epoch [71] | D Loss: 0.0393 | G Loss: 5.2716\n",
            "Epoch [72] | D Loss: 0.0542 | G Loss: 5.2548\n",
            "Epoch [73] | D Loss: 0.0323 | G Loss: 5.4082\n",
            "Epoch [74] | D Loss: 0.0381 | G Loss: 5.2369\n",
            "Epoch [75] | D Loss: 0.0606 | G Loss: 4.8048\n",
            "Epoch [76] | D Loss: 0.0334 | G Loss: 5.5305\n",
            "Epoch [77] | D Loss: 0.0209 | G Loss: 5.7534\n",
            "Epoch [78] | D Loss: 0.0346 | G Loss: 6.1257\n",
            "Epoch [79] | D Loss: 0.0604 | G Loss: 5.9002\n",
            "Epoch [80] | D Loss: 0.0312 | G Loss: 5.2685\n",
            "Epoch [81] | D Loss: 0.0463 | G Loss: 5.3539\n",
            "Epoch [82] | D Loss: 0.0199 | G Loss: 6.1049\n",
            "Epoch [83] | D Loss: 0.0128 | G Loss: 5.5071\n",
            "Epoch [84] | D Loss: 0.0449 | G Loss: 5.7330\n",
            "Epoch [85] | D Loss: 0.0144 | G Loss: 5.6495\n",
            "Epoch [86] | D Loss: 0.0215 | G Loss: 5.8192\n",
            "Epoch [87] | D Loss: 0.0562 | G Loss: 6.0353\n",
            "Epoch [88] | D Loss: 0.0194 | G Loss: 5.6829\n",
            "Epoch [89] | D Loss: 0.0115 | G Loss: 5.7488\n",
            "Epoch [90] | D Loss: 0.0278 | G Loss: 6.0979\n",
            "Epoch [91] | D Loss: 0.0181 | G Loss: 5.5718\n",
            "Epoch [92] | D Loss: 0.0088 | G Loss: 5.2212\n",
            "Epoch [93] | D Loss: 0.0143 | G Loss: 5.4239\n",
            "Epoch [94] | D Loss: 0.0180 | G Loss: 5.8835\n",
            "Epoch [95] | D Loss: 0.0075 | G Loss: 5.3908\n",
            "Epoch [96] | D Loss: 0.0107 | G Loss: 5.5604\n",
            "Epoch [97] | D Loss: 0.0183 | G Loss: 5.7463\n",
            "Epoch [98] | D Loss: 0.0084 | G Loss: 5.2171\n",
            "Epoch [99] | D Loss: 0.0099 | G Loss: 5.4700\n"
          ]
        }
      ]
    }
  ]
}